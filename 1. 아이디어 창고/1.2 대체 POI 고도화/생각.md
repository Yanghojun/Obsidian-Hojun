시나리오
	선택한 POI와 유사한 POI를 추천
		1. 현재 선택한 POI 정보
		2. User 개인 선호 정보
		3. 나와 비슷한 다른 User 들의 방문 정보
	예상되는 단점
		Cold start: 나와 비슷한 선호를 갖는 user의 부족

Trajectory 모델링이 필요할까?
	음식점 추천을 생각해봤을때, 유저의 선호를 결정할 땐 유저가 어떤 음식점들을 갔는지 Pin 꼽으면 됌. Sequence는 의미 없음. Sequence간 유사한 음식점을 가지도 않을것이고.

# 우리가 가진 데이터로 뭘 할 수 있나?
- 문제 정의를 위해 생각해보자.
User(운전자) - Item(POI)간 Adjacency Matrix
	User수, Item 수, Interaction수 보면 얼마나 Sparse한지 알 수 있을것.

POI Feature. 지리적 위치, 카테고리, cb, cc, cd 범주
User Feature. 사용할 만한게 있나..?


# 적용할 수 있는 방법은 뭐가 있을까?
- Contents based filtering
	- KG 그래프 (Metapath2vec)
		- POI - META
- Collaborative based filteirng
	- NGCF (Neural graph collaborative filtering)
		- User - POI Interaction

- Hybrid 추천
	- NGCF + MLP
		- User-POI Interaction과 POI category정보를 MLP로 넣으면 되지 않을까?
	- KG 그래프 (Metapath2vec)
		- USER - POI - META - POI - USER
			- **이게 user 방문 정보, POI 메타 정보를 모두 이용한 추천 결과일텐데..** 이상하지 않을까..?
			- 학습할 때 user 방문 정보, POI 메타 정보를 모두 사용한 것은 맞음
	- 위 방식들 모두 Graph 기반이라 Adjacency matrix가 너무 커짐. 이를 어찌할꼬..?


# 네이버는 Hybrid 추천을 어떻게 할까?
- Hybrid 추천: CB + CF
![[Pasted image 20250516104248.png]]

- CB를 강화하기 위해 LLM으로 유저 리뷰글에서 가게 정보 추가

시각화를 아래와 같이 할 수 있음.
- 왼쪽 그림: Contents based filtering 만으로 임베딩 한 결과
- 오른쪽 그림: Cb + Cf로 비건 식당이 보다 가까워진 모습.
![[Pasted image 20250516134308.png]]

아래 왼쪽그림: CB filtering
오른쪽 그림: CB + CF로 애견 동반 식당이 보다 가까워진 모습
![[Pasted image 20250516134433.png]]

성능 측정
Coverage: POI 수
POISAGE: Pinsage 기술로, User - POI 간 Interaction 있는 POI만 사용
LLM: Text Feature의 유사도만으로 추천 
LLM + User Interaction: 가장 높은 성능
![[Pasted image 20250516134623.png]]
```python
import torch
import torch.nn as nn
from torch_geometric.nn import LGConv

class LightGCNWithInteraction(nn.Module):
    def __init__(self, num_users, num_items, embed_dim, num_layers=3):
        super().__init__()
        self.user_embedding = nn.Embedding(num_users, embed_dim)
        self.item_embedding = nn.Embedding(num_items, embed_dim)
        self.brand_embedding = nn.Embedding(3, embed_dim)  # Nike, Adidas, Prospecs
        self.num_layers = num_layers
        self.conv = LGConv()

    def forward(self, edge_index, item_brand_ids, edge_weight=None):
        # embedding 초기화
        x_user = self.user_embedding.weight                             # [num_users, D]
        x_item = self.item_embedding.weight + self.brand_embedding(item_brand_ids)  # [num_items, D]
        x = torch.cat([x_user, x_item], dim=0)                          # [num_users + num_items, D]

        # propagation
        all_embeddings = [x]
        for _ in range(self.num_layers):
            x = self.conv(x, edge_index, edge_weight)
            all_embeddings.append(x)

        x = sum(all_embeddings) / (self.num_layers + 1)
        user_embeddings = x[:x_user.size(0)]
        item_embeddings = x[x_user.size(0):]
        return user_embeddings, item_embeddings

class BPRLoss(nn.Module):
    def __init__(self, l2_reg=1e-4):
        super().__init__()
        self.l2_reg = l2_reg

    def forward(self, user_emb, pos_item_emb, neg_item_emb):
        pos_scores = (user_emb * pos_item_emb).sum(dim=1)
        neg_scores = (user_emb * neg_item_emb).sum(dim=1)

        loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()

        # L2 정규화 (optional)
        l2 = (user_emb.norm(2).pow(2) +
              pos_item_emb.norm(2).pow(2) +
              neg_item_emb.norm(2).pow(2)) / user_emb.size(0)
        return loss + self.l2_reg * l2

def train(model, optimizer, bpr_loss_fn, edge_index, item_brand_ids, interactions, num_users, num_items, epochs=10):
    model.train()

    for epoch in range(epochs):
        total_loss = 0

        for (user_id, pos_item_id, _) in interactions:
            # 🔁 forward 를 여기서 다시
            user_emb_all, item_emb_all = model(edge_index, item_brand_ids)

            # 음성 샘플링
            while True:
                neg_item_id = torch.randint(0, num_items, (1,)).item()
                if (user_id, neg_item_id) not in [(u, i) for (u, i, _) in interactions]:
                    break

            u_emb = user_emb_all[user_id]
            pos_emb = item_emb_all[pos_item_id]
            neg_emb = item_emb_all[neg_item_id]

            loss = bpr_loss_fn(u_emb.unsqueeze(0), pos_emb.unsqueeze(0), neg_emb.unsqueeze(0))

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        print(f"Epoch {epoch+1:03d} | Loss: {total_loss:.4f}")

num_users = 3
num_items = 4
embed_dim = 16
item_brand_ids = torch.tensor([0, 1, 0, 2])  # 0:Nike, 1:Adidas, 2:Prospecs

# interactions = [(user, item, weight)]
interactions = [
    (0, 0, 1.0),
    (1, 2, 2.0),
    (2, 3, 1.0)
]

# edge_index, edge_weight
rows, cols, weights = [], [], []
for u, i, w in interactions:
    u_idx = u
    i_idx = num_users + i
    rows += [u_idx, i_idx]
    cols += [i_idx, u_idx]
    weights += [w, w]

edge_index = torch.tensor([rows, cols], dtype=torch.long)
edge_weight = torch.tensor(weights, dtype=torch.float)

# 모델, 옵티마이저, Loss
model = LightGCNWithInteraction(num_users, num_items, embed_dim)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
loss_fn = BPRLoss(l2_reg=1e-4)

# 학습
train(model, optimizer, loss_fn, edge_index, item_brand_ids, interactions, num_users, num_items, epochs=20)

# 추천: user_id가 선호할 top-k 아이템
def recommend(user_id, model, edge_index, item_brand_ids, top_k=3):
    model.eval()
    with torch.no_grad():
        user_embs, item_embs = model(edge_index, item_brand_ids)
        user_vec = user_embs[user_id]           # [D]
        scores = (user_vec * item_embs).sum(dim=1)  # [num_items]
        top_items = torch.topk(scores, top_k).indices
        return top_items.tolist()

# 예시: 유저 0에게 추천
recommended = recommend(0, model, edge_index, item_brand_ids)
print("추천 아이템:", recommended)

```