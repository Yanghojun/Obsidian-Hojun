# 이진분류 Loss 어떻게 구성되는지 스스로 생각해보기
내가 생각한 식
	- y=0일때 q=1 이면 서로 다르게 추론한것이고, 이럴 때 Loss값을 높이고 싶은것이니 위와 같이 처리
	- y=1일때 q=0 이면 서로 다르게 추론한것이고, 이럴 때 Loss값을 높이고 싶은것이니 위와 같이 처리
$$
q^{1-y}(1-q)^y
$$
혁펜하임 식
$$
-q^y(1-q)^{1-y}
$$

위 두 식이 서로 다른것인지에 대해 궁금.

- 다른지 증명

	```markdown
	두 식을 각각
	
	A=q 1−y(1−q)yA = q^{\,1-y}(1-q)^y B=− qy(1−q) 1−yB = -\,q^y(1-q)^{\,1-y}
	
	라고 하겠습니다.
	
	### 1. 식의 구조 비교
	
	- **첫 번째 식 AA:**  
	    qq에 1−y1-y의 지수, (1−q)(1-q)에 yy의 지수를 가지고 있습니다.
	    
	- **두 번째 식 BB:**  
	    qq에 yy의 지수, (1−q)(1-q)에 1−y1-y의 지수를 가지며, 전체에 음수 부호가 붙어 있습니다.
	    
	
	즉, 두 식은 지수의 위치가 서로 교환되어 있으며, 두 번째 식 앞에 추가적인 음수(-)가 붙어 있습니다.
	
	### 2. 두 식의 관계 확인
	
	두 식이 같다고 가정하면,
	
	q 1−y(1−q)y=− qy(1−q) 1−y.q^{\,1-y}(1-q)^y = -\,q^y(1-q)^{\,1-y}.
	
	양변을 비교하기 위해, 두 식의 비율 AB\frac{A}{B}를 구해 보면:
	
	AB=q1−y(1−q)y− qy(1−q)1−y=− q1−yqy (1−q)y(1−q)1−y.\frac{A}{B} = \frac{q^{1-y}(1-q)^y}{-\,q^y(1-q)^{1-y}} = -\,\frac{q^{1-y}}{q^y}\,\frac{(1-q)^y}{(1-q)^{1-y}}.
	
	지수를 정리하면
	
	AB=− q 1−y−y(1−q) y−(1−y)=− q 1−2y(1−q) 2y−1.\frac{A}{B} = -\,q^{\,1-y-y}(1-q)^{\,y-(1-y)} = -\,q^{\,1-2y}(1-q)^{\,2y-1}.
	
	따라서 두 식이 같으려면
	
	−q 1−2y(1−q) 2y−1=1-q^{\,1-2y}(1-q)^{\,2y-1} = 1
	
	이어야 하는데, qq와 1−q1-q가 일반적으로 양수인 경우 (예, q∈(0,1)q\in(0,1))에는 q 1−2y(1−q) 2y−1q^{\,1-2y}(1-q)^{\,2y-1}도 양수입니다.  
	즉, 좌변은 음수가 되고 우변은 양수이므로, 일반적으로 위 등식은 성립하지 않습니다.
	
	### 3. 구체적인 예
	
	- **y=0y=0일 때:**
	    
	    - A=q 1(1−q)0=qA = q^{\,1}(1-q)^0 = q
	    - B=− q0(1−q) 1=−(1−q)B = -\,q^0(1-q)^{\,1} = -(1-q)  
	        일반적으로 q≠−(1−q)q \neq -(1-q)입니다.
	- **y=1y=1일 때:**
	    
	    - A=q 0(1−q)1=1−qA = q^{\,0}(1-q)^1 = 1-q
	    - B=− q1(1−q)0=−qB = -\,q^1(1-q)^0 = -q  
	        역시 1−q1-q와 −q-q는 같지 않습니다.
	
	### 4. 결론
	
	두 식은
	
	q 1−y(1−q)y와− qy(1−q) 1−yq^{\,1-y}(1-q)^y \quad \text{와} \quad -\,q^y(1-q)^{\,1-y}
	
	로 나타내어지며, 지수의 위치가 서로 바뀌고 두 번째 식 앞에 음수 부호가 붙어 있기 때문에, 일반적인 qq (예: q∈(0,1)q\in(0,1))와 yy의 값에 대해 **서로 다른 값**을 갖습니다.
	
	단, 두 식이 모두 0이 되는 극단적인 경우(예: q=0q=0 또는 q=1q=1)에는 값이 같을 수 있으나, 보통의 경우에는 두 식은 **같지 않다**고 할 수 있습니다.
	
	```
- 위 두 식을 Loss로 썼을 때 이진분류 task에서의 성능 차이
	```markdown
	"식을 등식으로 둔다는 것"은 수학적으로 두 표현(혹은 함수)이 동일하다는 것을 명시적으로 나타내는 것을 의미합니다. 구체적으로:
	
	1. **정의와 동등성:**  
	    예를 들어,
	    
	    L(y,q)=q1−y(1−q)yL(y,q) = q^{1-y}(1-q)^y
	    
	    라고 등식으로 정의하면, 좌변 L(y,q)L(y,q)는 우변 q1−y(1−q)yq^{1-y}(1-q)^y와 모든 yy와 qq의 값(정의역 내)에서 정확히 같은 값을 가진다고 주장하는 것입니다.
	    
	2. **두 식 비교 시 의미:**  
	    만약 두 loss 함수가
	    
	    L1(y,q)=q1−y(1−q)y와L2(y,q)=−qy(1−q)1−yL_1(y,q) = q^{1-y}(1-q)^y \quad \text{와} \quad L_2(y,q) = -q^y(1-q)^{1-y}
	    
	    와 같이 주어졌을 때, "식을 등식으로 둔다"는 것은 L1(y,q)=L2(y,q)L_1(y,q) = L_2(y,q)라고 선언하는 것과 같습니다. 이때 두 함수가 모든 yy와 qq에 대해 정확히 동일한 값을 가져야 등식이 성립하게 됩니다.
	    
	3. **실제 적용 시 고려사항:**  
	    실제 머신러닝에서 loss 함수를 설계할 때, 두 식이 상수항 차이나 변수의 순서만 다르고 미분 값(gradient)이 동일하다면, 학습 과정에서는 영향을 주지 않을 수 있습니다. 하지만 수학적으로 등식을 세울 때는 모든 항들이 정확히 일치해야 한다는 점을 강조하는 것입니다.
	    
	
	요약하면, 식을 등식으로 둔다는 것은 "두 식이 같은 값을 갖는다"는 것을 전제하거나 정의하는 것이며, 이는 문제를 풀거나 모델을 최적화할 때 해당 관계를 엄격히 적용한다는 의미입니다.
	```


# 역전파 (BackPropagation)
- 핵심: 특정 Layer의 Weight가 Loss에 어떻게 영향을 주는지 알아내는 것.
- 합성함수의 미분을 통해 Loss부터 특정 Layer의 Weight까지 한단계씩 접근.

항상 아래 그림으로 생각할 것.
![[Pasted image 20250328031510.png]]

$$
W_2 \rightarrow 들_2 \rightarrow 나_2 \rightarrow \hat
$$