# AutoGrad
- 추가 필요
# nn.Linear
- 데이터 `feature`수를 늘려줌.
- 데이터 shape이 복잡해도, 결국 가장 중요한건 맨 마지막의 데이터 `feature 수` 이다.
```python
import torch
from torch import nn
x = torch.randn((2,), requires_grad = True)

fc1 = nn.Linear(2, 3)

fc1(x).shape  # (3)


# 만약 데이터가 여러개라면?
# 5명의 학생의 키, 몸무게 데이터
x = torch.randn((5,2), requires_grad=True)

fc1(x).shape  # (5,3)


# 만약 데이터가 아주 여러개라면?
# 5명의 학생이 4개조를 이룬 3개 학년이 모인 2개 학교에 대해서 키, 몸무게 데이터를 인공신경망에 넣는다면?
x = torch.randn((2,3,4,5,2), requires_grad = True)

fc1(x).shape  # (2,3,4,5,3)
```

# 1D Conv
![[Pasted image 20250509131707.png]]
이해를 위해 1시간마다 3개 센서가 값을 측정해서 데이터가 축척되었다고 하자.
하루치 데이터의 shape은 (24, 3) 이다.
여기에 1D Conv를 적용하면
`in_channels`: 입력 데이터의 차원 수
- 이 값으로 인해 2차원 모양의 필터가 생성된다. 1D Conv라고 필터 모양이 1차원이어야 하는게 아니다.
- 2D Conv도 RGB 입력 처리를 위해 3차원 필터 생성하는걸 생각하자.
- 2D Conv가 흑백 이미지에 대해선 2차원 필터 생성하는걸 생각하면, 여기서도 1개 센서 값 일 때 1차원 필터가 생성되는 것이다.
`out_channels`: 필터 수
- `in_channels` 값으로 형성된 필터를 몇개 설정할건지
``

```

```